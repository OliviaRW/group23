{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-23T15:30:03.634114Z",
     "start_time": "2017-08-23T15:30:03.629294Z"
    }
   },
   "source": [
    "# Exercise Set 12: Linear regression models.\n",
    "\n",
    "*Afternoon, August 19, 2019*\n",
    "\n",
    "In this Exercise Set 12 we will work with linear regression models.\n",
    "\n",
    "We import our standard stuff. Notice that we are not interested in seeing the convergence warning in scikit-learn so we suppress them for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(action='ignore', category=ConvergenceWarning)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Section 12.1: Estimating linear models with gradient decent\n",
    " \n",
    "Normally we use OLS to estimate linear models. In this exercise we replace the OLS-estimator with a new estimator that we code up from scratch. We solve the numerical optimization using the gradient decent algorithm. Using our algorithm we will fit it to some data, and compare our own solution to the standard solution from `sklearn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 12.1.0**: Import the dataset `tips` from the `seaborn`.\n",
    "\n",
    "\n",
    "*Hint*: use the `load_dataset` method in seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>tip</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.99</td>\n",
       "      <td>1.01</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.34</td>\n",
       "      <td>1.66</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.01</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.68</td>\n",
       "      <td>3.31</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.59</td>\n",
       "      <td>3.61</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25.29</td>\n",
       "      <td>4.71</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.77</td>\n",
       "      <td>2.00</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>26.88</td>\n",
       "      <td>3.12</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15.04</td>\n",
       "      <td>1.96</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14.78</td>\n",
       "      <td>3.23</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_bill   tip     sex smoker  day    time  size\n",
       "0       16.99  1.01  Female     No  Sun  Dinner     2\n",
       "1       10.34  1.66    Male     No  Sun  Dinner     3\n",
       "2       21.01  3.50    Male     No  Sun  Dinner     3\n",
       "3       23.68  3.31    Male     No  Sun  Dinner     2\n",
       "4       24.59  3.61  Female     No  Sun  Dinner     4\n",
       "5       25.29  4.71    Male     No  Sun  Dinner     4\n",
       "6        8.77  2.00    Male     No  Sun  Dinner     2\n",
       "7       26.88  3.12    Male     No  Sun  Dinner     4\n",
       "8       15.04  1.96    Male     No  Sun  Dinner     2\n",
       "9       14.78  3.23    Male     No  Sun  Dinner     2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tips = sns.load_dataset('tips')\n",
    "tips.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 12.1.1**: Convert non-numeric variables to dummy variables for each category (remember to leave one column out for each catagorical variable, so you have a reference). Restructure the data so we get a dataset `y` containing the variable tip, and a dataset `X` containing the \n",
    "features. \n",
    "\n",
    ">> *Hint*: You might want to use the `get_dummies` method in pandas, with the `drop_first = True` parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>tip</th>\n",
       "      <th>sex_Female</th>\n",
       "      <th>smoker_No</th>\n",
       "      <th>day_Fri</th>\n",
       "      <th>day_Sat</th>\n",
       "      <th>day_Sun</th>\n",
       "      <th>time_Dinner</th>\n",
       "      <th>size_2</th>\n",
       "      <th>size_3</th>\n",
       "      <th>size_4</th>\n",
       "      <th>size_5</th>\n",
       "      <th>size_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.99</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.34</td>\n",
       "      <td>1.66</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.01</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.68</td>\n",
       "      <td>3.31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.59</td>\n",
       "      <td>3.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25.29</td>\n",
       "      <td>4.71</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.77</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>26.88</td>\n",
       "      <td>3.12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15.04</td>\n",
       "      <td>1.96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14.78</td>\n",
       "      <td>3.23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_bill   tip  sex_Female  smoker_No  day_Fri  day_Sat  day_Sun  \\\n",
       "0       16.99  1.01           1          1        0        0        1   \n",
       "1       10.34  1.66           0          1        0        0        1   \n",
       "2       21.01  3.50           0          1        0        0        1   \n",
       "3       23.68  3.31           0          1        0        0        1   \n",
       "4       24.59  3.61           1          1        0        0        1   \n",
       "5       25.29  4.71           0          1        0        0        1   \n",
       "6        8.77  2.00           0          1        0        0        1   \n",
       "7       26.88  3.12           0          1        0        0        1   \n",
       "8       15.04  1.96           0          1        0        0        1   \n",
       "9       14.78  3.23           0          1        0        0        1   \n",
       "\n",
       "   time_Dinner  size_2  size_3  size_4  size_5  size_6  \n",
       "0            1       1       0       0       0       0  \n",
       "1            1       0       1       0       0       0  \n",
       "2            1       0       1       0       0       0  \n",
       "3            1       1       0       0       0       0  \n",
       "4            1       0       0       1       0       0  \n",
       "5            1       0       0       1       0       0  \n",
       "6            1       1       0       0       0       0  \n",
       "7            1       0       0       1       0       0  \n",
       "8            1       1       0       0       0       0  \n",
       "9            1       1       0       0       0       0  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tips_dummies = pd.get_dummies(tips, columns = ['sex', 'smoker', 'day', 'time', 'size'], drop_first = True)\n",
    "X = tips_dummies.drop('tip', axis = 1)\n",
    "y = tips_dummies['tip']\n",
    "tips_dummies.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 12.1.2**: Divide the features and target into test and train data. Make the split 50 pct. of each. The split data should be called `X_train`, `X_test`, `y_train`, `y_test`.\n",
    "\n",
    ">> *Hint*: You may use `train_test_split` in `sklearn.model_selection`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test =\\\n",
    "    train_test_split(X, y, \n",
    "                     test_size = 0.5, \n",
    "                     random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 12.1.3**: Normalize your features by converting to zero mean and one std. deviation.\n",
    "\n",
    ">> *Hint 1*: Take a look at `StandardScaler` in `sklearn.preprocessing`. \n",
    "\n",
    ">> *Hint 2*: If in doubt about which distribution to scale, you may read [this post](https://stats.stackexchange.com/questions/174823/how-to-apply-standardization-normalization-to-train-and-testset-if-prediction-i)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype uint8, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype uint8, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype uint8, float64 were all converted to float64 by StandardScaler.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "#https://sebastianraschka.com/faq/docs/scale-training-test.html\n",
    "stdsc = StandardScaler()\n",
    "X_train_std = stdsc.fit_transform(X_train)\n",
    "X_test_std = stdsc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 12.1.4**: Make a function called `compute_error` to compute the prediction errors given input target `y_`, input features `X_` and input weights `w_`. You should use matrix multiplication.\n",
    ">\n",
    ">> *Hint 1:* You can use the net-input fct. from yesterday.\n",
    ">>\n",
    ">> *Hint 2:* If you run the following code,\n",
    ">> ```python\n",
    "y__ = np.array([1,1])\n",
    "X__ = np.array([[1,0],[0,1]])\n",
    "w__ = np.array([0,1,1])\n",
    "compute_error(y__, X__, w__)\n",
    "```\n",
    "\n",
    ">> then you should get output:\n",
    "```python \n",
    "array([0,0])\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_input(X, w):\n",
    "    return w[0] + np.dot(X, w[1:])\n",
    "\n",
    "def predict(X, w):\n",
    "    return net_input(X, w)\n",
    "\n",
    "def compute_error(y_, X_, w_):\n",
    "    return np.where(y_ != predict(X_, w_), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y__ = np.array([1,1])\n",
    "X__ = np.array([[1,0],[0,1]])\n",
    "w__ = np.array([0.,1.,1.])\n",
    "compute_error(y__, X__, w__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 12.1.5**: Make a function to update the weights given input target `y_`, input features `X_` and input weights `w_` as well as learning rate, $\\eta$, i.e. greek `eta`. You should use matrix multiplication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 12.1.6**: Use the code below to initialize weights `w` at zero given feature set `X`. Notice how we include an extra weight that includes the bias term. Set the learning rate `eta` to 0.001. Make a loop with 50 iterations where you iteratively apply your weight updating function. \n",
    "\n",
    ">```python\n",
    "w = np.zeros(1+X.shape[1])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def fit(X_, y_, n_iter, eta):\n",
    "    w_ = np.zeros(1+X.shape[1]) #initialization of weights\n",
    "    \n",
    "    MSEs = [] #To collect mean-squared-errors\n",
    "    for _ in range(n_iter):\n",
    "        updates = (y_-(w_[0] + np.dot(X_, w_[1:]))) #updates contains a vector of updates\n",
    "        w_[1:] += eta * np.dot(X_.T, updates)\n",
    "        w_[0] += eta * updates.sum()\n",
    "        \n",
    "        y_pred = w_[0] + np.dot(X_, w_[1:]) #This is a prediction of all the y's using linear algebra\n",
    "        MSEs.append(mean_squared_error(y_, y_pred))\n",
    "        \n",
    "    return w_, MSEs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 12.1.7**: Make a function to compute the mean squared error. Alter the loop so it makes 100 iterations and computes the MSE for test and train after each iteration, plot these in one figure. \n",
    "\n",
    ">> Hint: You can use the following code to check that your model works:\n",
    ">>```python\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train, y_train)\n",
    "assert((w[1:] - reg.coef_).sum() < 0.01)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA9MAAAD8CAYAAAB0H/c7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAF1JJREFUeJzt3X+MZWd9HvDn2/FYDE7REJhG7BjXRiVDLNywaIVIjFBqaBcCgZWVqqSlTZGr7R+oAZRu5O0fYbdKZKqN0qRKiroCAlEpaeIsW0RVNlH4kSZS3IwZygJm0pSfnnXwonQcCENYL2//mBlndz2795713Lnnznw+0sp73zm+5znS8fE+e97znmqtBQAAABje3xh3AAAAAJg0yjQAAAB0pEwDAABAR8o0AAAAdKRMAwAAQEfKNAAAAHSkTAMAAEBHyjQAAAB0pEwDAABARzeM4kuf/exnt1tvvXUUXw0AAAAj8+CDD369tTY3aLuRlOlbb701i4uLo/hqAAAAGJmq+vIw25nmDQAAAB0p0wAAANCRMg0AAAAdKdMAAADQkTINAAAAHSnTAAAA0NFIXo01CU4vreTEmeWcW13LvtmZHDm4kEP758cdCwAAgAmwJ8v06aWVHD11NmsXLiZJVlbXcvTU2SRRqAEAABhoT07zPnFm+YkivWntwsWcOLM8pkQAAABMkj1Zps+trnUaBwAAgEvtyTK9b3am0zgAAABcak+W6SMHFzIzPXXZ2Mz0VI4cXBhTIgAAACbJUGW6qt5WVZ+tqs9U1Qeq6mmjDjZKh/bP576778j87EwqyfzsTO67+w6LjwEAADCUgat5V9V8kp9Kcntrba2qfjPJG5K8d8TZRurQ/nnlGQAAgOsy7DTvG5LMVNUNSZ6e5NzoIgEAAEC/DSzTrbWVJL+Q5CtJHknyWGvtd67crqoOV9ViVS2eP39++5MCAABATwws01X1zCSvT3Jbkn1JbqqqN165XWvtZGvtQGvtwNzc3PYnBQAAgJ4YZpr3K5N8sbV2vrV2IcmpJD882lgAAADQX8OU6a8keWlVPb2qKskrkjw02lgAAADQX8M8M/1AkvuTfDLJ2Y1/5+SIcwEAAEBvDXw1VpK01t6e5O0jzgIAAAATYdhXYwEAAAAblGkAAADoSJkGAACAjpRpAAAA6EiZBgAAgI6UaQAAAOhImQYAAICOlGkAAADoSJkGAACAjpRpAAAA6EiZBgAAgI6UaQAAAOhImQYAAICOlGkAAADoSJkGAACAjpRpAAAA6EiZBgAAgI6UaQAAAOhoYJmuqoWq+tQlv/6iqt66E+EAAACgj24YtEFrbTnJi5KkqqaSrCT54IhzAQAAQG91neb9iiT/t7X25VGEAQAAgEnQtUy/IckHtvpBVR2uqsWqWjx//vxTTwYAAAA9NXSZrqobk7wuyW9t9fPW2snW2oHW2oG5ubntygcAAAC90+XO9KuTfLK19rVRhQEAAIBJ0KVM/0SuMsUbAAAA9pKhynRVPT3J309yarRxAAAAoP8GvhorSVpr30ryrBFnAQAAgInQdTVvAAAA2POUaQAAAOhImQYAAICOlGkAAADoSJkGAACAjoZazXsvOr20khNnlnNudS37Zmdy5OBCDu2fH3csAAAAekCZ3sLppZUcPXU2axcuJklWVtdy9NTZJFGoAQAAMM17KyfOLD9RpDetXbiYE2eWx5QIAACAPlGmt3Buda3TOAAAAHuLMr2FfbMzncYBAADYW5TpLRw5uJCZ6anLxmamp3Lk4MKYEgEAANAnFiDbwuYiY1bzBgAAYCvK9FUc2j+vPAMAALAl07wBAACgI2UaAAAAOlKmAQAAoCNlGgAAADpSpgEAAKCjocp0Vc1W1f1V9fmqeqiqfmjUwQAAAKCvhn011i8n+Uhr7cer6sYkTx9hJgAAAOi1gWW6qp6R5OVJ/nmStNa+k+Q7o40FAAAA/TXMNO/nJTmf5Neqaqmq3lVVN125UVUdrqrFqlo8f/78tgcFAACAvhimTN+Q5MVJ3tla25/kL5Pce+VGrbWTrbUDrbUDc3Nz2xwTAAAA+mOYMv1wkodbaw9sfL4/6+UaAAAA9qSBZbq19mdJvlpVCxtDr0jyuZGmAgAAgB4bdjXvf5Xk/RsreX8hyZtGFwkAAAD6bagy3Vr7VJIDI84CAAAAE2GYZ6YBAACASyjTAAAA0JEyDQAAAB0p0wAAANCRMg0AAAAdKdMAAADQkTINAAAAHSnTAAAA0JEyDQAAAB0p0wAAANCRMg0AAAAdKdMAAADQkTINAAAAHd0w7gCT7PTSSk6cWc651bXsm53JkYMLObR/ftyxAAAAGDFl+jqdXlrJ0VNns3bhYpJkZXUtR0+dTRKFGgAAYJczzfs6nTiz/ESR3rR24WJOnFkeUyIAAAB2ijJ9nc6trnUaBwAAYPdQpq/TvtmZTuMAAADsHkOV6ar6UlWdrapPVdXiqENNgiMHFzIzPXXZ2Mz0VI4cXBhTIgAAAHZKlwXI/l5r7esjSzJhNhcZs5o3AADA3mM176fg0P555RkAAGAPGvaZ6Zbkd6rqwao6vNUGVXW4qharavH8+fPblxAAAAB6ZtgyfWdr7cVJXp3kzVX18is3aK2dbK0daK0dmJub29aQAAAA0CdDlenW2rmNfz6a5INJXjLKUAAAANBnA8t0Vd1UVX9z8/dJ/kGSz4w6GAAAAPTVMAuQfV+SD1bV5vb/pbX2kZGmAgAAgB4bWKZba19I8oM7kAUAAAAmwrALkAEAAAAblGkAAADoSJkGAACAjpRpAAAA6EiZBgAAgI6UaQAAAOhImQYAAICOlGkAAADoSJkGAACAjpRpAAAA6EiZBgAAgI6UaQAAAOjohnEH2O1OL63kxJnlnFtdy77ZmRw5uJBD++fHHQsAAICnQJkeodNLKzl66mzWLlxMkqysruXoqbNJolADAABMMNO8R+jEmeUnivSmtQsXc+LM8pgSAQAAsB2U6RE6t7rWaRwAAIDJoEyP0L7ZmU7jAAAATAZleoSOHFzIzPTUZWMz01M5cnBhTIkAAADYDkMvQFZVU0kWk6y01l47uki7x+YiY1bzBgAA2F26rOb9liQPJXnGiLLsSof2zyvPAAAAu8xQ07yr6uYkr0nyrtHGAQAAgP4b9pnpX0ryM0m+e7UNqupwVS1W1eL58+e3JRwAAAD00cAyXVWvTfJoa+3Ba23XWjvZWjvQWjswNze3bQEBAACgb4a5M31nktdV1ZeS/EaSu6rqP480FQAAAPTYwDLdWjvaWru5tXZrkjck+Whr7Y0jTwYAAAA95T3TAAAA0FGXV2OltfbxJB8fSRIAAACYEO5MAwAAQEfKNAAAAHSkTAMAAEBHyjQAAAB0pEwDAABAR8o0AAAAdNTp1ViMxumllZw4s5xzq2vZNzuTIwcXcmj//LhjAQAAcBXK9JidXlrJ0VNns3bhYpJkZXUtR0+dTRKFGgAAoKdM8x6zE2eWnyjSm9YuXMyJM8tjSgQAAMAgyvSYnVtd6zQOAADA+CnTY7ZvdqbTOAAAAOOnTI/ZkYMLmZmeumxsZnoqRw4ujCkRAAAAg1iAbMw2FxmzmjcAAMDkUKZ74ND+eeUZAABggpjmDQAAAB0p0wAAANCRMg0AAAAdKdMAAADQ0cAyXVVPq6r/VVX/u6o+W1XHdyIYAAAA9NUwq3n/VZK7WmvfrKrpJH9QVf+jtfZHI84GAAAAvTSwTLfWWpJvbnyc3vjVRhkKAAAA+myo90xX1VSSB5P8nSS/2lp7YIttDic5nCS33HLLdmbc804vreTEmeWcW13LvtmZHDm44L3UAAAAYzTUAmSttYuttRcluTnJS6rqhVtsc7K1dqC1dmBubm67c+5Zp5dWcvTU2aysrqUlWVldy9FTZ3N6aWXc0QAAAPasTqt5t9ZWk3w8yatGkoYnOXFmOWsXLl42tnbhYk6cWR5TIgAAAIZZzXuuqmY3fj+T5JVJPj/qYKw7t7rWaRwAAIDRG+bO9HOSfKyqPp3kj5P8bmvtw6ONxaZ9szOdxgEAABi9gWW6tfbp1tr+1trfba29sLX2b3ciGOuOHFzIzPTUZWMz01M5cnBhTIkAAAAYajVvxmdz1W6reQMAAPSHMj0BDu2fV54BAAB6pNNq3gAAAIAyDQAAAJ0p0wAAANCRMg0AAAAdWYBslzi9tGLFbwAAgB2iTO8Cp5dWcvTU2axduJgkWVldy9FTZ5NEoQYAABgB07x3gRNnlp8o0pvWLlzMiTPLY0oEAACwuynTu8C51bVO4wAAADw1yvQusG92ptM4AAAAT40yvQscObiQmempy8Zmpqdy5ODCmBIBAADsbhYg2wU2FxmzmjcAAMDOUKZ3iUP755VnAACAHWKaNwAAAHTkzvQecnppxVRwAACAbaBM7xGnl1Zy9NTZJ95HvbK6lqOnziaJQg0AANCRad57xIkzy08U6U1rFy7mxJnlMSUCAACYXAPLdFU9t6o+VlUPVdVnq+otOxGM7XVuda3TOAAAAFc3zJ3px5P8dGvtB5K8NMmbq+r20cZiu+2bnek0DgAAwNUNLNOttUdaa5/c+P03kjyUxEO2E+bIwYXMTE9dNjYzPZUjBxfGlAgAAGBydVqArKpuTbI/yQNb/OxwksNJcsstt2xDNLbT5iJjVvMGAAB46qq1NtyGVd+T5BNJfr61dupa2x44cKAtLi5uQzx2kldnAQAAe11VPdhaOzBou6HuTFfVdJLfTvL+QUWayeTVWQAAAMMbZjXvSvLuJA+11n5x9JEYB6/OAgAAGN4wq3nfmeSfJrmrqj618etHR5yLHebVWQAAAMMbOM27tfYHSWoHsjBG+2ZnsrJFcfbqLAAAgCcb5s40e4BXZwEAAAyv06ux2L2GfXWWFb8BAACUaS5xaP/8NYuxFb8BAADWmebN0Kz4DQAAsE6ZZmhW/AYAAFhnmjdDG3bFb89VAwAAu5070wxtmBW/N5+rXlldS8tfP1d9emllh9MCAACMjjLN0A7tn899d9+R+dmZVJL52Zncd/cdl9119lw1AACwF5jmTSeDVvwe9rlqU8EBAIBJ5s402+rK56e3GjcVHAAAmHTKNNtqmOeqTQUHAAAmnWnebKvNqdrXmsI9zFRw08ABAIA+U6bZdoOeqx70iq3NaeCbd683p4FvfjcAAMC4mebNjhs0FXzYaeCnl1Zy5zs+mtvu/e+58x0f9cw1AACwY9yZZscNmgo+7DTwYe5emy4OAACMgjLNWFxrKvigaeDJte9eb37vMIVb2QYAAK6Had70zjArgg9z93rQdPFhX9FlOjkAAHAld6bpnWFWBB/m7vWgwr1dd7c3t3OHGwAA9o6BZbqq3pPktUkeba29cPSRYPCK4EcOLlxWcpMn370eVLif6t3t7S7cwxRypR0AAPphmDvT703yK0l+fbRRYHjD3L0eVLi34+72ZoanWriHfb67T6W9L/vpUxbH7C+BAIC9Y2CZbq39flXdOvoo0M2gu9eDCvd23N1OtqdwD1PI+1Ta+7KfPmVxzKP9S6Bhtpm0v0CYpCy7bT99yuKYHfNuzeKYJ38/O5llUk0dO3Zs4EbHjx+fTfKPjx079h+vtk1VHT5+/Ph/On78+OHp6el9b3vb27YxJlyfFzznGbnnZbflra/8/tzzstvyguc847Kf3fzMmZxdeSzf/PbjmZ+dyc/+2O2X/cf9rJtuzCf+5Hwe/257Ymxmeio/+2O3P/Fdv7X4cL7x7ceftO/52Znc87LbkiQ/9+HPbZnvm99+PG995fcP/Pkw35Ek97xvMX/+re9c9vPHv9tyduWx3POy2wb+fJjv6NN++pTFMV//fjYL9+Z23/j24/nEn5zPzc+ceeK/s0HbbMd39Gk/fcqy2/bTpyyO2TE75t2TZbftZyez9NHx48cfOXbs2MlB223bat6ttZOttQOttQNzc3Pb9bUwUof2z+cP770rX3zHa/KH9971pL8lO7R/PvfdfUfmZ2dSWS/I9919x5Omkw9affzSO9mX2hwf9PNhtxl0l3yYu+jbsc1O7adPWRzz9e9n0Mr7w2yzHd/Rp/30Kctu20+fsjhmx+yYd0+W3bafncwyybwaCwbYicI9TCHvU2nvy376lMUxX/9++lTs+7KfPmXZbfvpUxbHPLr99CmLYx7dfvqUZbftZyezTDJlGrbBUy3cwxTyPpX2vuynT1kc8/Xvp0/Fvi/76VOW3bafPmVxzKPbT5+yOObR7adPWXbbfnYyyyQb+Mx0VX0gyc8lueX48eP/8vjx448dO3Zs6Vr/zsmTJ48dPnx4+1LCLnCt57eH+fmw33Gt58CHeU58O7bZqf30KYtjvv79DLM2waBttuM7+rSfPmXZbfvpUxbH7Jgd8+7Jstv2s5NZ+mjYZ6artTZom84OHDjQFhcXt/17Adid+rSiaF/206csu20/fcrimB3zbs3imCd/PzuZpW+q6sHW2oGB2ynTAAAAsG7YMu2ZaQAAAOhImQYAAICOlGkAAADoSJkGAACAjpRpAAAA6Ggkq3lX1fkkX972Lx6NZyf5+rhDQEfOWyaR85ZJ5LxlUjl3mUR9OW//dmttbtBGIynTk6SqFodZ9hz6xHnLJHLeMomct0wq5y6TaNLOW9O8AQAAoCNlGgAAADpSppOT4w4A18F5yyRy3jKJnLdMKucuk2iizts9/8w0AAAAdOXONAAAAHS0Z8t0Vb2qqpar6k+r6t5x54GtVNVzq+pjVfVQVX22qt6yMf69VfW7VfV/Nv75zHFnhStV1VRVLVXVhzc+31ZVD2yct/+1qm4cd0a4UlXNVtX9VfX5jWvvD7nm0ndV9baNPyd8pqo+UFVPc82lb6rqPVX1aFV95pKxLa+vte4/bHS1T1fVi8eX/Or2ZJmuqqkkv5rk1UluT/ITVXX7eFPBlh5P8tOttR9I8tIkb944V+9N8nuttecn+b2Nz9A3b0ny0CWf/12Sf79x3v6/JPeMJRVc2y8n+Uhr7QVJfjDr57BrLr1VVfNJfirJgdbaC5NMJXlDXHPpn/cmedUVY1e7vr46yfM3fh1O8s4dytjJnizTSV6S5E9ba19orX0nyW8kef2YM8GTtNYeaa19cuP338j6H+rms36+vm9js/clOTSehLC1qro5yWuSvGvjcyW5K8n9G5s4b+mdqnpGkpcneXeStNa+01pbjWsu/XdDkpmquiHJ05M8Etdceqa19vtJ/vyK4atdX1+f5Nfbuj9KMltVz9mZpMPbq2V6PslXL/n88MYY9FZV3Zpkf5IHknxfa+2RZL1wJ/lb40sGW/qlJD+T5Lsbn5+VZLW19vjGZ9dd+uh5Sc4n+bWNRxTeVVU3xTWXHmutrST5hSRfyXqJfizJg3HNZTJc7fo6EX1tr5bp2mLMsub0VlV9T5LfTvLW1tpfjDsPXEtVvTbJo621By8d3mJT11365oYkL07yztba/iR/GVO66bmNZ0xfn+S2JPuS3JT1KbJXcs1lkkzEnxv2apl+OMlzL/l8c5JzY8oC11RV01kv0u9vrZ3aGP7a5lSXjX8+Oq58sIU7k7yuqr6U9cdo7sr6nerZjSmIiesu/fRwkodbaw9sfL4/6+XaNZc+e2WSL7bWzrfWLiQ5leSH45rLZLja9XUi+tpeLdN/nOT5G6sc3pj1RRo+NOZM8CQbz5m+O8lDrbVfvORHH0rykxu//8kk/22ns8HVtNaOttZubq3dmvXr60dba/8kyceS/PjGZs5beqe19mdJvlpVCxtDr0jyubjm0m9fSfLSqnr6xp8bNs9b11wmwdWurx9K8s82VvV+aZLHNqeD90m11ru75Tuiqn4063dKppK8p7X282OOBE9SVS9L8j+TnM1fP3v6b7L+3PRvJrkl6/8T/YettSsXdICxq6ofSfKvW2uvrarnZf1O9fcmWUryxtbaX40zH1ypql6U9YXzbkzyhSRvyvrNB9dcequqjif5R1l/C8hSkn+R9edLXXPpjar6QJIfSfLsJF9L8vYkp7PF9XXjL4Z+Jeurf38ryZtaa4vjyH0te7ZMAwAAwPXaq9O8AQAA4Lop0wAAANCRMg0AAAAdKdMAAADQkTINAAAAHSnTAAAA0JEyDQAAAB0p0wAAANDR/weUT+zeQ5oxxAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1224x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "w, MSEs = fit(X_train_std, y_train, 100, 0.001)\n",
    "fig, ax = plt.subplots(figsize = (17,4))\n",
    "ax.scatter(x = range(len(MSEs)), y = MSEs, label = 'MSEs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following bonus exercises are for those who have completed all other exercises until now and have a deep motivation for learning more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 12.1.8 (BONUS)**: Implement your linear regression model as a class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 12.1.9 (BONUS)**: Is it possible to adjust our linear model to become a Lasso? Is there a simple fix?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Section 12.2: Houseprices\n",
    "In this example we will try to predict houseprices using a lot of variable (or features as they are called in Machine Learning). We are going to work with Kaggle's dataset on house prices, see information [here](https://www.kaggle.com/c/house-prices-advanced-regression-techniques). Kaggle is an organization that hosts competitions in building predictive models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 12.2.0:** Load the california housing data with scikit-learn using the code below. Inspect the data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556\n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842\n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260\n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945\n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cal_house = fetch_california_housing()    \n",
    "X = pd.DataFrame(data=cal_house['data'], \n",
    "                 columns=cal_house['feature_names'])\\\n",
    "             .iloc[:,:-2]\n",
    "y = cal_house['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5, random_state=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "> **Ex.12.2.1**: Generate interactions between all features to third degree, make sure you **exclude** the bias/intercept term. How many variables are there? Will OLS fail? \n",
    "\n",
    "> After making interactions rescale the features to have zero mean, unit std. deviation. Should you use the distribution of the training data to rescale the test data?  \n",
    "\n",
    ">> *Hint 1*: Try importing `PolynomialFeatures` from `sklearn.preprocessing`\n",
    "\n",
    ">> *Hint 2*: If in doubt about which distribution to scale, you may read [this post](https://stats.stackexchange.com/questions/174823/how-to-apply-standardization-normalization-to-train-and-testset-if-prediction-i)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of variables: 83\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "X_p = PolynomialFeatures(degree = 3, include_bias = False).fit_transform(X_train)\n",
    "print('Amount of variables: {}'.format(len(X_p[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex.12.2.2**: Estimate the Lasso model on the train data set, using values of $\\lambda$ in the range from $10^{-4}$ to $10^4$. For each $\\lambda$  calculate and save the Root Mean Squared Error (RMSE) for the test and train data. \n",
    "\n",
    "> *Hint*: use `logspace` in numpy to create the range.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "rng = np.logspace(-6, 6, base = 10)\n",
    "train_RMSE = []\n",
    "test_RMSE = []\n",
    "for lmbd in rng:\n",
    "    lasso = Lasso(lmbd)\n",
    "    lasso.fit(X_train, y_train)\n",
    "    y_train_pred = lasso.predict(X_train)\n",
    "    y_test_pred = lasso.predict(X_test)\n",
    "    \n",
    "    train_RMSE.append(mean_squared_error(y_train, \n",
    "                                         y_train_pred)**(1/2))\n",
    "    test_RMSE.append(mean_squared_error(y_test, \n",
    "                                         y_test_pred)**(1/2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex.12.2.3**: Make a plot with on the x-axis and the RMSE measures on the y-axis. What happens to RMSE for train and test data as $\\lambda$ increases? The x-axis should be log scaled. Which one are we interested in minimizing? \n",
    "\n",
    "> Bonus: Can you find the lambda that gives the lowest MSE-test score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize = (15, 4))\n",
    "ax.scatter(x = np.log10(rng), y = train_RMSE, label = 'Train RMSE')\n",
    "ax.scatter(x = np.log10(rng), y = test_RMSE, label = 'Test RMSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda minimizing RMSE: 1e-06\n"
     ]
    }
   ],
   "source": [
    "pos = np.argmin(test_RMSE)\n",
    "print('Lambda minimizing RMSE: {}'.format(rng[pos]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
